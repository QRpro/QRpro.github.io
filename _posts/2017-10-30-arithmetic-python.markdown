---
layout:     post
title:      "算法入门-常用排序算法-python版"
subtitle:   "代码不重要，解决问题的思想最重要"
date:       2017-08-17 
header-img: "img/arithmetic-bg-1710.jpg"
catalog:    true
author:     "Neil"
tags:
    - Python
    - 数据结构与算法
---  

## 写在前面的话  
许久没有更新博客，最近看的东西比较杂没有静下心来整理。说到工作最近手头上工作在移植PHP的服务器代码转用Java实现，看完Java再看python和php突然就会发现Java的弊端`开发效率低、体系繁杂且笨重`，当然这也是相对而言，Java的第三方库也是极为强大的。  
这次更新一下排序算法相关的知识点，顺便当做一次复习。对算法这部分不是特别熟悉，虽然经过资料翻阅，但难免有错，如文中有错误，请及时指正。
后期应该会开始更新设计模式相关的博文。

## 概念性的东西
#### 相关术语
先抛出几个重要但是不难懂的概念
> 评述算法优劣术语的说明  

- 稳定：如果a原本在b前面，而a=b，排序之后a仍然在b的前面；
- 不稳定：如果a原本在b的前面，而a=b，排序之后a可能会出现在b的后面；
- 内排序：所有排序操作都在内存中完成；
- 外排序：由于数据太大，因此把数据放在磁盘中，而排序通过磁盘和内存的数据传输才能进行；
- 时间复杂度: 一个算法执行所耗费的时间。
- 空间复杂度: 运行完一个程序所需内存的大小。

#### 时间复杂度与“大O记法
假定计算机执行算法每一个基本操作的时间是固定的一个时间单位，那么有多少个基本操作就代表会花费多少时间单位。然而对于不同的机器环境而言，确切的单位时间是不同的，但是对于算法进行多少个基本操作（即花费多少时间单位）在规模数量级上却是相同的，由此可以`忽略机器环境的影响而客观的反应算法的时间效率`。

**“大O记法”：**对于单调的整数函数f，如果存在一个整数函数g和实常数c>0，使得对于充分大的n总有f(n)<=c*g(n)，就说函数g是f的一个渐近函数（忽略常数），记为f(n)=O(g(n))。也就是说，在趋向无穷的极限意义下，函数f的增长速度受到函数g的约束，亦即函数f与函数g的特征相似。说白了就是f(n)约等于g(n)但是不能划等号所以就用大O包了一圈。  
**时间复杂度：**假设存在函数g，使得算法A处理规模为n的问题示例所用时间为T(n)=O(g(n))，则称O(g(n))为算法A的渐近时间复杂度，简称时间复杂度，记为T(n)
对于算法进行特别具体的细致分析虽然很好，但在实践中的实际价值有限。计量算法基本操作数量的规模函数中那些常量因子可以忽略不计。例如，可以认为3n2和100n2属于同一个量级，如果两个算法处理同样规模实例的代价分别为这两个函数，就认为它们的效率“差不多”，都为n2级。  

#### 最坏时间复杂度
分析算法时，存在几种可能的考虑：

- 算法完成工作最少需要多少基本操作，即`最优时间复杂度`，其`价值不大`，因为它没有提供什么有用信息，其反映的只是最乐观最理想的情况，没有参考价值。
- 算法完成工作最多需要多少基本操作，即`最坏时间复杂度`，提供保证，表明算法在此种程度的基本操作中一定能完成工作。
- 算法完成工作平均需要多少基本操作，即`平均时间复杂度`，一个全面评价，因此它完整全面的反映了这个算法的性质。但另一方面，这种衡量并没有保证，不是每个计算都能在这个基本操作内完成。而且，对于平均情况的计算，也会因为应用算法的实例分布可能并不均匀而`难以计算`。

因此，我们主要`关注`算法的最坏情况，亦即**`最坏时间复杂度。`**

#### 基本计算规则

1.	基本操作，即只有常数项，认为其时间复杂度为O(1)
2.	顺序结构，时间复杂度按加法进行计算
3.	循环结构，时间复杂度按乘法进行计算
4.	分支结构，时间复杂度取最大值
5.	判断一个算法的效率时，往往只需要关注操作数量的最高次项，其它次要项和常数项可以忽略
6.	在没有特殊说明时，我们所分析的算法的时间复杂度都是指最坏时间复杂度

#### 常见时间复杂度
![img](/img/blogarticles/algorithm/Common-time-complexity.png)  

所消耗的时间从小到大
O(1) < O(logn) < O(n) < O(nlogn) < O(n2) < O(n3) < O(2n) < O(n!) < O(nn)

## 常见算法
#### 冒泡排序(Bubble Sort)
应该是我们接触过的最早的一个排序算法，也是最简单的一个，它重复地遍历要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。遍历数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成

> 冒泡排序算法的运作如下：

- 比较相邻的元素。如果第一个比第二个大（升序），就交换他们两个。
- 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。
- 针对所有的元素重复以上的步骤，除了最后一个。
- 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。

![img](/img/blogarticles/algorithm/bubble-sort-png.gif)  

> 代码如下：  

```
def bubble_sort3(alist):
    for j in range(len(alist)-1,0,-1):
        # j表示每次遍历需要比较的次数，是逐渐减小的
        for i in range(j):
            if alist[i] > alist[i+1]:
                alist[i], alist[i+1] = alist[i+1], alist[i]
```

> 时间复杂度 

- 最优时间复杂度：O(n) （表示遍历一次发现没有任何可以交换的元素，排序结束。）
- 最坏时间复杂度：O(n2)
- 稳定性：稳定

#### 选择排序(Selection sort)  
表现最稳定的排序算法之一(这个稳定不是指算法层面上的稳定哈，相信聪明的你能明白我说的意思2333)，因为无论什么数据进去都是O(n²)的时间复杂度…..所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。理论上讲，选择排序可能也是平时排序一般人想到的最多的排序方法。

> 选择排序算法的运作如下： 

首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕  
![img](/img/blogarticles/algorithm/select-sort-gif.gif)  

``` 
def selection_sort(alist):
    n = len(alist)
    # 需要进行n-1次选择操作
    for i in range(n-1):
        # 记录最小位置
        min_index = i
        # 从i+1位置到末尾选择出最小数据
        for j in range(i+1, n):
            if alist[j] < alist[min_index]:
                min_index = j
        # 如果选择出的数据不在正确位置，进行交换
        if min_index != i:
            alist[i], alist[min_index] = alist[min_index], alist[i]

alist = [54,226,93,17,77,31,44,55,20]
selection_sort(alist)
print(alist)
```

> 时间复杂度 

- 最优时间复杂度：O(n2)
- 最坏时间复杂度：O(n2)
- 稳定性：不稳定（考虑升序每次选择最大的情况）

#### 插入排序 (Insertion Sort)
一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间，原理应该是最容易理解的了，因为只要打过扑克牌的人都应该能够秒懂。

![img](/img/blogarticles/algorithm/insert-sort-gif.gif)  

```
def insert_sort(alist):
    # 从第二个位置，即下标为1的元素开始向前插入
    for i in range(1, len(alist)):
        # 从第i个元素开始向前比较，如果小于前一个元素，交换位置
        for j in range(i, 0, -1):
            if alist[j] < alist[j-1]:
                alist[j], alist[j-1] = alist[j-1], alist[j]

alist = [54,26,93,17,77,31,44,55,20]
insert_sort(alist)
print(alist)
```

> 时间复杂度 

- 最优时间复杂度：O(n) （升序排列，序列已经处于升序状态）
- 最坏时间复杂度：O(n2)
- 稳定性：稳定

#### 希尔排序(Shell Sort)
是插入排序的一种。也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。该方法因DL．Shell于1959年提出而得名。 希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。  

![img](/img/blogarticles/algorithm/shell-sort.png)  
```
def shell_sort(alist):
    n = len(alist)
    # 初始步长
    gap = n / 2
    while gap > 0:
        # 按步长进行插入排序
        for i in range(gap, n):
            j = i
            # 插入排序
            while j>=gap and alist[j-gap] > alist[j]:
                alist[j-gap], alist[j] = alist[j], alist[j-gap]
                j -= gap
        # 得到新的步长
        gap = gap / 2

alist = [54,26,93,17,77,31,44,55,20]
shell_sort(alist)
print(alist)

``` 


> 时间复杂度 

- 最优时间复杂度：根据步长序列的不同而不同
- 最坏时间复杂度：O(n2)        
- 稳定想：不稳定  

#### 快速排序(Quicksort)
通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。  

> 快速排序算法的运作如下：

- 从数列中挑出一个元素，称为"基准"（pivot），
- 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。
- 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。  

递归的最底部情形，是数列的大小是零或一，也就是永远都已经被排序好了。虽然一直递归下去，但是这个算法总会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去 

![img](/img/blogarticles/algorithm/q-s-gif.gif)  

```
def quick_sort(alist, start, end):
    """快速排序"""

    # 递归的退出条件
    if start >= end:
        return

    # 设定起始元素为要寻找位置的基准元素
    mid = alist[start]

    # low为序列左边的由左向右移动的游标
    low = start

    # high为序列右边的由右向左移动的游标
    high = end

    while low < high:
        # 如果low与high未重合，high指向的元素不比基准元素小，则high向左移动
        while low < high and alist[high] >= mid:
            high -= 1
        # 将high指向的元素放到low的位置上
        alist[low] = alist[high]

        # 如果low与high未重合，low指向的元素比基准元素小，则low向右移动
        while low < high and alist[low] < mid:
            low += 1
        # 将low指向的元素放到high的位置上
        alist[high] = alist[low]

    # 退出循环后，low与high重合，此时所指位置为基准元素的正确位置
    # 将基准元素放到该位置
    alist[low] = mid

    # 对基准元素左边的子序列进行快速排序
    quick_sort(alist, start, low-1)

    # 对基准元素右边的子序列进行快速排序
    quick_sort(alist, low+1, end)


alist = [54,26,93,17,77,31,44,55,20]
quick_sort(alist,0,len(alist)-1)
print(alist)

```  

> 时间复杂度 

- 最优时间复杂度：O(nlogn)
- 最坏时间复杂度：O(n2)        
- 稳定想：不稳定 

#### 归并排序(Merge Sort) 
归并排序是采用分治法的一个非常典型的应用。归并排序的思想就是先递归分解数组，再合并数组。将数组分解最小之后，然后合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另一个数组的剩余部分复制过来即可。 

![img](/img/blogarticles/algorithm/Merge-Sort-gif.gif)  
```
def merge_sort(alist):
    if len(alist) <= 1:
        return alist
    # 二分分解
    num = len(alist)/2
    left = merge_sort(alist[:num])
    right = merge_sort(alist[num:])
    # 合并
    return merge(left,right)

def merge(left, right):
    '''合并操作，将两个有序数组left[]和right[]合并成一个大的有序数组'''
    #left与right的下标指针
    l, r = 0, 0
    result = []
    while l<len(left) and r<len(right):
        if left[l] < right[r]:
            result.append(left[l])
            l += 1
        else:
            result.append(right[r])
            r += 1
    result += left[l:]
    result += right[r:]
    return result

alist = [54,26,93,17,77,31,44,55,20]
sorted_alist = mergeSort(alist)
print(sorted_alist)
```
- 最优时间复杂度：O(nlogn)
- 最坏时间复杂度：O(nlogn)
- 稳定想：稳定 

--- 
上述算法思想还是很重要的，理解了思想代码实现起来也不是很复杂，如果从中只挑一个的话，推荐快速排序，务必掌握。

--Neil 后记于2017.10